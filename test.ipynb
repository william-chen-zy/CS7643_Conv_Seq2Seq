{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "# import VAE as VAE\n",
    "import VAE.DataLoader as DataLoader\n",
    "import VAE.Encoder as Encoder\n",
    "import VAE.Decoder as Decoder\n",
    "import VAE.ConvSeq2Seq as ConvSeq2Seq\n",
    "import VAE.Discriminator as Discriminator\n",
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading subject 1, action walking, subaction 1\n",
      "Reading subject 1, action walking, subaction 2\n",
      "Reading subject 1, action eating, subaction 1\n",
      "Reading subject 1, action eating, subaction 2\n",
      "Reading subject 1, action smoking, subaction 1\n",
      "Reading subject 1, action smoking, subaction 2\n",
      "Reading subject 1, action discussion, subaction 1\n",
      "Reading subject 1, action discussion, subaction 2\n",
      "Reading subject 1, action directions, subaction 1\n",
      "Reading subject 1, action directions, subaction 2\n",
      "Reading subject 1, action greeting, subaction 1\n",
      "Reading subject 1, action greeting, subaction 2\n",
      "Reading subject 1, action phoning, subaction 1\n",
      "Reading subject 1, action phoning, subaction 2\n",
      "Reading subject 1, action posing, subaction 1\n",
      "Reading subject 1, action posing, subaction 2\n",
      "Reading subject 1, action purchases, subaction 1\n",
      "Reading subject 1, action purchases, subaction 2\n",
      "Reading subject 1, action sitting, subaction 1\n",
      "Reading subject 1, action sitting, subaction 2\n",
      "Reading subject 1, action sittingdown, subaction 1\n",
      "Reading subject 1, action sittingdown, subaction 2\n",
      "Reading subject 1, action takingphoto, subaction 1\n",
      "Reading subject 1, action takingphoto, subaction 2\n",
      "Reading subject 1, action waiting, subaction 1\n",
      "Reading subject 1, action waiting, subaction 2\n",
      "Reading subject 1, action walkingdog, subaction 1\n",
      "Reading subject 1, action walkingdog, subaction 2\n",
      "Reading subject 1, action walkingtogether, subaction 1\n",
      "Reading subject 1, action walkingtogether, subaction 2\n",
      "Reading subject 6, action walking, subaction 1\n",
      "Reading subject 6, action walking, subaction 2\n",
      "Reading subject 6, action eating, subaction 1\n",
      "Reading subject 6, action eating, subaction 2\n",
      "Reading subject 6, action smoking, subaction 1\n",
      "Reading subject 6, action smoking, subaction 2\n",
      "Reading subject 6, action discussion, subaction 1\n",
      "Reading subject 6, action discussion, subaction 2\n",
      "Reading subject 6, action directions, subaction 1\n",
      "Reading subject 6, action directions, subaction 2\n",
      "Reading subject 6, action greeting, subaction 1\n",
      "Reading subject 6, action greeting, subaction 2\n",
      "Reading subject 6, action phoning, subaction 1\n",
      "Reading subject 6, action phoning, subaction 2\n",
      "Reading subject 6, action posing, subaction 1\n",
      "Reading subject 6, action posing, subaction 2\n",
      "Reading subject 6, action purchases, subaction 1\n",
      "Reading subject 6, action purchases, subaction 2\n",
      "Reading subject 6, action sitting, subaction 1\n",
      "Reading subject 6, action sitting, subaction 2\n",
      "Reading subject 6, action sittingdown, subaction 1\n",
      "Reading subject 6, action sittingdown, subaction 2\n",
      "Reading subject 6, action takingphoto, subaction 1\n",
      "Reading subject 6, action takingphoto, subaction 2\n",
      "Reading subject 6, action waiting, subaction 1\n",
      "Reading subject 6, action waiting, subaction 2\n",
      "Reading subject 6, action walkingdog, subaction 1\n",
      "Reading subject 6, action walkingdog, subaction 2\n",
      "Reading subject 6, action walkingtogether, subaction 1\n",
      "Reading subject 6, action walkingtogether, subaction 2\n",
      "Reading subject 7, action walking, subaction 1\n",
      "Reading subject 7, action walking, subaction 2\n",
      "Reading subject 7, action eating, subaction 1\n",
      "Reading subject 7, action eating, subaction 2\n",
      "Reading subject 7, action smoking, subaction 1\n",
      "Reading subject 7, action smoking, subaction 2\n",
      "Reading subject 7, action discussion, subaction 1\n",
      "Reading subject 7, action discussion, subaction 2\n",
      "Reading subject 7, action directions, subaction 1\n",
      "Reading subject 7, action directions, subaction 2\n",
      "Reading subject 7, action greeting, subaction 1\n",
      "Reading subject 7, action greeting, subaction 2\n",
      "Reading subject 7, action phoning, subaction 1\n",
      "Reading subject 7, action phoning, subaction 2\n",
      "Reading subject 7, action posing, subaction 1\n",
      "Reading subject 7, action posing, subaction 2\n",
      "Reading subject 7, action purchases, subaction 1\n",
      "Reading subject 7, action purchases, subaction 2\n",
      "Reading subject 7, action sitting, subaction 1\n",
      "Reading subject 7, action sitting, subaction 2\n",
      "Reading subject 7, action sittingdown, subaction 1\n",
      "Reading subject 7, action sittingdown, subaction 2\n",
      "Reading subject 7, action takingphoto, subaction 1\n",
      "Reading subject 7, action takingphoto, subaction 2\n",
      "Reading subject 7, action waiting, subaction 1\n",
      "Reading subject 7, action waiting, subaction 2\n",
      "Reading subject 7, action walkingdog, subaction 1\n",
      "Reading subject 7, action walkingdog, subaction 2\n",
      "Reading subject 7, action walkingtogether, subaction 1\n",
      "Reading subject 7, action walkingtogether, subaction 2\n",
      "Reading subject 8, action walking, subaction 1\n",
      "Reading subject 8, action walking, subaction 2\n",
      "Reading subject 8, action eating, subaction 1\n",
      "Reading subject 8, action eating, subaction 2\n",
      "Reading subject 8, action smoking, subaction 1\n",
      "Reading subject 8, action smoking, subaction 2\n",
      "Reading subject 8, action discussion, subaction 1\n",
      "Reading subject 8, action discussion, subaction 2\n",
      "Reading subject 8, action directions, subaction 1\n",
      "Reading subject 8, action directions, subaction 2\n",
      "Reading subject 8, action greeting, subaction 1\n",
      "Reading subject 8, action greeting, subaction 2\n",
      "Reading subject 8, action phoning, subaction 1\n",
      "Reading subject 8, action phoning, subaction 2\n",
      "Reading subject 8, action posing, subaction 1\n",
      "Reading subject 8, action posing, subaction 2\n",
      "Reading subject 8, action purchases, subaction 1\n",
      "Reading subject 8, action purchases, subaction 2\n",
      "Reading subject 8, action sitting, subaction 1\n",
      "Reading subject 8, action sitting, subaction 2\n",
      "Reading subject 8, action sittingdown, subaction 1\n",
      "Reading subject 8, action sittingdown, subaction 2\n",
      "Reading subject 8, action takingphoto, subaction 1\n",
      "Reading subject 8, action takingphoto, subaction 2\n",
      "Reading subject 8, action waiting, subaction 1\n",
      "Reading subject 8, action waiting, subaction 2\n",
      "Reading subject 8, action walkingdog, subaction 1\n",
      "Reading subject 8, action walkingdog, subaction 2\n",
      "Reading subject 8, action walkingtogether, subaction 1\n",
      "Reading subject 8, action walkingtogether, subaction 2\n",
      "Reading subject 9, action walking, subaction 1\n",
      "Reading subject 9, action walking, subaction 2\n",
      "Reading subject 9, action eating, subaction 1\n",
      "Reading subject 9, action eating, subaction 2\n",
      "Reading subject 9, action smoking, subaction 1\n",
      "Reading subject 9, action smoking, subaction 2\n",
      "Reading subject 9, action discussion, subaction 1\n",
      "Reading subject 9, action discussion, subaction 2\n",
      "Reading subject 9, action directions, subaction 1\n",
      "Reading subject 9, action directions, subaction 2\n",
      "Reading subject 9, action greeting, subaction 1\n",
      "Reading subject 9, action greeting, subaction 2\n",
      "Reading subject 9, action phoning, subaction 1\n",
      "Reading subject 9, action phoning, subaction 2\n",
      "Reading subject 9, action posing, subaction 1\n",
      "Reading subject 9, action posing, subaction 2\n",
      "Reading subject 9, action purchases, subaction 1\n",
      "Reading subject 9, action purchases, subaction 2\n",
      "Reading subject 9, action sitting, subaction 1\n",
      "Reading subject 9, action sitting, subaction 2\n",
      "Reading subject 9, action sittingdown, subaction 1\n",
      "Reading subject 9, action sittingdown, subaction 2\n",
      "Reading subject 9, action takingphoto, subaction 1\n",
      "Reading subject 9, action takingphoto, subaction 2\n",
      "Reading subject 9, action waiting, subaction 1\n",
      "Reading subject 9, action waiting, subaction 2\n",
      "Reading subject 9, action walkingdog, subaction 1\n",
      "Reading subject 9, action walkingdog, subaction 2\n",
      "Reading subject 9, action walkingtogether, subaction 1\n",
      "Reading subject 9, action walkingtogether, subaction 2\n",
      "Reading subject 11, action walking, subaction 1\n",
      "Reading subject 11, action walking, subaction 2\n",
      "Reading subject 11, action eating, subaction 1\n",
      "Reading subject 11, action eating, subaction 2\n",
      "Reading subject 11, action smoking, subaction 1\n",
      "Reading subject 11, action smoking, subaction 2\n",
      "Reading subject 11, action discussion, subaction 1\n",
      "Reading subject 11, action discussion, subaction 2\n",
      "Reading subject 11, action directions, subaction 1\n",
      "Reading subject 11, action directions, subaction 2\n",
      "Reading subject 11, action greeting, subaction 1\n",
      "Reading subject 11, action greeting, subaction 2\n",
      "Reading subject 11, action phoning, subaction 1\n",
      "Reading subject 11, action phoning, subaction 2\n",
      "Reading subject 11, action posing, subaction 1\n",
      "Reading subject 11, action posing, subaction 2\n",
      "Reading subject 11, action purchases, subaction 1\n",
      "Reading subject 11, action purchases, subaction 2\n",
      "Reading subject 11, action sitting, subaction 1\n",
      "Reading subject 11, action sitting, subaction 2\n",
      "Reading subject 11, action sittingdown, subaction 1\n",
      "Reading subject 11, action sittingdown, subaction 2\n",
      "Reading subject 11, action takingphoto, subaction 1\n",
      "Reading subject 11, action takingphoto, subaction 2\n",
      "Reading subject 11, action waiting, subaction 1\n",
      "Reading subject 11, action waiting, subaction 2\n",
      "Reading subject 11, action walkingdog, subaction 1\n",
      "Reading subject 11, action walkingdog, subaction 2\n",
      "Reading subject 11, action walkingtogether, subaction 1\n",
      "Reading subject 11, action walkingtogether, subaction 2\n",
      "Reading subject 5, action walking, subaction 1\n",
      "Reading subject 5, action walking, subaction 2\n",
      "Reading subject 5, action eating, subaction 1\n",
      "Reading subject 5, action eating, subaction 2\n",
      "Reading subject 5, action smoking, subaction 1\n",
      "Reading subject 5, action smoking, subaction 2\n",
      "Reading subject 5, action discussion, subaction 1\n",
      "Reading subject 5, action discussion, subaction 2\n",
      "Reading subject 5, action directions, subaction 1\n",
      "Reading subject 5, action directions, subaction 2\n",
      "Reading subject 5, action greeting, subaction 1\n",
      "Reading subject 5, action greeting, subaction 2\n",
      "Reading subject 5, action phoning, subaction 1\n",
      "Reading subject 5, action phoning, subaction 2\n",
      "Reading subject 5, action posing, subaction 1\n",
      "Reading subject 5, action posing, subaction 2\n",
      "Reading subject 5, action purchases, subaction 1\n",
      "Reading subject 5, action purchases, subaction 2\n",
      "Reading subject 5, action sitting, subaction 1\n",
      "Reading subject 5, action sitting, subaction 2\n",
      "Reading subject 5, action sittingdown, subaction 1\n",
      "Reading subject 5, action sittingdown, subaction 2\n",
      "Reading subject 5, action takingphoto, subaction 1\n",
      "Reading subject 5, action takingphoto, subaction 2\n",
      "Reading subject 5, action waiting, subaction 1\n",
      "Reading subject 5, action waiting, subaction 2\n",
      "Reading subject 5, action walkingdog, subaction 1\n",
      "Reading subject 5, action walkingdog, subaction 2\n",
      "Reading subject 5, action walkingtogether, subaction 1\n",
      "Reading subject 5, action walkingtogether, subaction 2\n",
      "done reading data.\n"
     ]
    }
   ],
   "source": [
    "dloader = DataLoader.DataLoader(50, 25, './data/h3.6m/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_data, discriminator_data, yhat = dloader.get_train_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_data = torch.Tensor(encoder_data)\n",
    "discriminator_data = torch.Tensor(discriminator_data)\n",
    "yhat = torch.Tensor(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 49, 54, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 75, 54, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'VAE.Discriminator' from '/home/wichen/repos/CS7643_DL/Project/VAE/Discriminator.py'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(Encoder)\n",
    "reload(Decoder)\n",
    "reload(ConvSeq2Seq)\n",
    "reload(Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_encoder = Encoder.Encoder(3,enc_shape=[None, 20, 54, 1], enc_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_encoder = Encoder.Encoder(3, enc_dim=527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder.Decoder(st_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_encoder = Encoder.Encoder(32, enc_dim=512, enc_shape=[None, 75,54,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ConvSeq2Seq.ConvSeq2Seq(lt_encoder, decoder, window_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_output:  torch.Size([32, 527])\n"
     ]
    }
   ],
   "source": [
    "test = generator.forward(encoder_data, discriminator_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator.Discriminator(32, d_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = discriminator.forward(discriminator_data,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_criterion = nn.MSELoss()\n",
    "D_criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_seq, predicted_action, generated_sample = generator.forward(encoder_data, discriminator_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_seq = discriminator_data[:, 50:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25, 54, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25, 54, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 75, 54, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReconstructError = G_criterion(predicted_seq, expected_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_logits_real = discriminator.forward(discriminator_data, yhat)\n",
    "d_logits_fake = discriminator.forward(generated_sample, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = torch.mean(D_criterion(d_logits_real, torch.ones_like(d_logits_real)))\n",
    "d_loss_fake = torch.mean(D_criterion(d_logits_fake, torch.zeros_like(d_logits_fake)))\n",
    "g_loss = torch.mean(D_criterion(d_logits_fake, torch.ones_like(d_logits_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3958, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7648, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1738, 54)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dloader.train_set[(1,'walking', 1, 'even')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = VAE.EncoderBase(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint( 16, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 10, 2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{0}/S{1}/{2}_{3}.txt'.format('./data/h3.6m/dataset', 1, 'walking', 1)\n",
    "action_sequence = data_utils.readCSVasFloat(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3476, 99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e9b5e93101e5958f9cd028a9f43ed128e885f27a05c22831a3d71acc3bca11d"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
