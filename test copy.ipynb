{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "# import VAE as VAE\n",
    "import VAE.DataLoader as DataLoader\n",
    "import VAE.Encoder as Encoder\n",
    "import VAE.Decoder as Decoder\n",
    "import VAE.ConvSeq2Seq as ConvSeq2Seq\n",
    "import VAE.Discriminator as Discriminator\n",
    "import util as util\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '/home/wichen/repos/CS7643_DL/Project/util.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(Encoder)\n",
    "reload(Decoder)\n",
    "reload(ConvSeq2Seq)\n",
    "reload(Discriminator)\n",
    "reload(DataLoader)\n",
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading subject 1, action walking, subaction 1\n",
      "Reading subject 1, action walking, subaction 2\n",
      "Reading subject 1, action eating, subaction 1\n",
      "Reading subject 1, action eating, subaction 2\n",
      "Reading subject 1, action smoking, subaction 1\n",
      "Reading subject 1, action smoking, subaction 2\n",
      "Reading subject 1, action discussion, subaction 1\n",
      "Reading subject 1, action discussion, subaction 2\n",
      "Reading subject 1, action directions, subaction 1\n",
      "Reading subject 1, action directions, subaction 2\n",
      "Reading subject 1, action greeting, subaction 1\n",
      "Reading subject 1, action greeting, subaction 2\n",
      "Reading subject 1, action phoning, subaction 1\n",
      "Reading subject 1, action phoning, subaction 2\n",
      "Reading subject 1, action posing, subaction 1\n",
      "Reading subject 1, action posing, subaction 2\n",
      "Reading subject 1, action purchases, subaction 1\n",
      "Reading subject 1, action purchases, subaction 2\n",
      "Reading subject 1, action sitting, subaction 1\n",
      "Reading subject 1, action sitting, subaction 2\n",
      "Reading subject 1, action sittingdown, subaction 1\n",
      "Reading subject 1, action sittingdown, subaction 2\n",
      "Reading subject 1, action takingphoto, subaction 1\n",
      "Reading subject 1, action takingphoto, subaction 2\n",
      "Reading subject 1, action waiting, subaction 1\n",
      "Reading subject 1, action waiting, subaction 2\n",
      "Reading subject 1, action walkingdog, subaction 1\n",
      "Reading subject 1, action walkingdog, subaction 2\n",
      "Reading subject 1, action walkingtogether, subaction 1\n",
      "Reading subject 1, action walkingtogether, subaction 2\n",
      "Reading subject 6, action walking, subaction 1\n",
      "Reading subject 6, action walking, subaction 2\n",
      "Reading subject 6, action eating, subaction 1\n",
      "Reading subject 6, action eating, subaction 2\n",
      "Reading subject 6, action smoking, subaction 1\n",
      "Reading subject 6, action smoking, subaction 2\n",
      "Reading subject 6, action discussion, subaction 1\n",
      "Reading subject 6, action discussion, subaction 2\n",
      "Reading subject 6, action directions, subaction 1\n",
      "Reading subject 6, action directions, subaction 2\n",
      "Reading subject 6, action greeting, subaction 1\n",
      "Reading subject 6, action greeting, subaction 2\n",
      "Reading subject 6, action phoning, subaction 1\n",
      "Reading subject 6, action phoning, subaction 2\n",
      "Reading subject 6, action posing, subaction 1\n",
      "Reading subject 6, action posing, subaction 2\n",
      "Reading subject 6, action purchases, subaction 1\n",
      "Reading subject 6, action purchases, subaction 2\n",
      "Reading subject 6, action sitting, subaction 1\n",
      "Reading subject 6, action sitting, subaction 2\n",
      "Reading subject 6, action sittingdown, subaction 1\n",
      "Reading subject 6, action sittingdown, subaction 2\n",
      "Reading subject 6, action takingphoto, subaction 1\n",
      "Reading subject 6, action takingphoto, subaction 2\n",
      "Reading subject 6, action waiting, subaction 1\n",
      "Reading subject 6, action waiting, subaction 2\n",
      "Reading subject 6, action walkingdog, subaction 1\n",
      "Reading subject 6, action walkingdog, subaction 2\n",
      "Reading subject 6, action walkingtogether, subaction 1\n",
      "Reading subject 6, action walkingtogether, subaction 2\n",
      "Reading subject 7, action walking, subaction 1\n",
      "Reading subject 7, action walking, subaction 2\n",
      "Reading subject 7, action eating, subaction 1\n",
      "Reading subject 7, action eating, subaction 2\n",
      "Reading subject 7, action smoking, subaction 1\n",
      "Reading subject 7, action smoking, subaction 2\n",
      "Reading subject 7, action discussion, subaction 1\n",
      "Reading subject 7, action discussion, subaction 2\n",
      "Reading subject 7, action directions, subaction 1\n",
      "Reading subject 7, action directions, subaction 2\n",
      "Reading subject 7, action greeting, subaction 1\n",
      "Reading subject 7, action greeting, subaction 2\n",
      "Reading subject 7, action phoning, subaction 1\n",
      "Reading subject 7, action phoning, subaction 2\n",
      "Reading subject 7, action posing, subaction 1\n",
      "Reading subject 7, action posing, subaction 2\n",
      "Reading subject 7, action purchases, subaction 1\n",
      "Reading subject 7, action purchases, subaction 2\n",
      "Reading subject 7, action sitting, subaction 1\n",
      "Reading subject 7, action sitting, subaction 2\n",
      "Reading subject 7, action sittingdown, subaction 1\n",
      "Reading subject 7, action sittingdown, subaction 2\n",
      "Reading subject 7, action takingphoto, subaction 1\n",
      "Reading subject 7, action takingphoto, subaction 2\n",
      "Reading subject 7, action waiting, subaction 1\n",
      "Reading subject 7, action waiting, subaction 2\n",
      "Reading subject 7, action walkingdog, subaction 1\n",
      "Reading subject 7, action walkingdog, subaction 2\n",
      "Reading subject 7, action walkingtogether, subaction 1\n",
      "Reading subject 7, action walkingtogether, subaction 2\n",
      "Reading subject 8, action walking, subaction 1\n",
      "Reading subject 8, action walking, subaction 2\n",
      "Reading subject 8, action eating, subaction 1\n",
      "Reading subject 8, action eating, subaction 2\n",
      "Reading subject 8, action smoking, subaction 1\n",
      "Reading subject 8, action smoking, subaction 2\n",
      "Reading subject 8, action discussion, subaction 1\n",
      "Reading subject 8, action discussion, subaction 2\n",
      "Reading subject 8, action directions, subaction 1\n",
      "Reading subject 8, action directions, subaction 2\n",
      "Reading subject 8, action greeting, subaction 1\n",
      "Reading subject 8, action greeting, subaction 2\n",
      "Reading subject 8, action phoning, subaction 1\n",
      "Reading subject 8, action phoning, subaction 2\n",
      "Reading subject 8, action posing, subaction 1\n",
      "Reading subject 8, action posing, subaction 2\n",
      "Reading subject 8, action purchases, subaction 1\n",
      "Reading subject 8, action purchases, subaction 2\n",
      "Reading subject 8, action sitting, subaction 1\n",
      "Reading subject 8, action sitting, subaction 2\n",
      "Reading subject 8, action sittingdown, subaction 1\n",
      "Reading subject 8, action sittingdown, subaction 2\n",
      "Reading subject 8, action takingphoto, subaction 1\n",
      "Reading subject 8, action takingphoto, subaction 2\n",
      "Reading subject 8, action waiting, subaction 1\n",
      "Reading subject 8, action waiting, subaction 2\n",
      "Reading subject 8, action walkingdog, subaction 1\n",
      "Reading subject 8, action walkingdog, subaction 2\n",
      "Reading subject 8, action walkingtogether, subaction 1\n",
      "Reading subject 8, action walkingtogether, subaction 2\n",
      "Reading subject 9, action walking, subaction 1\n",
      "Reading subject 9, action walking, subaction 2\n",
      "Reading subject 9, action eating, subaction 1\n",
      "Reading subject 9, action eating, subaction 2\n",
      "Reading subject 9, action smoking, subaction 1\n",
      "Reading subject 9, action smoking, subaction 2\n",
      "Reading subject 9, action discussion, subaction 1\n",
      "Reading subject 9, action discussion, subaction 2\n",
      "Reading subject 9, action directions, subaction 1\n",
      "Reading subject 9, action directions, subaction 2\n",
      "Reading subject 9, action greeting, subaction 1\n",
      "Reading subject 9, action greeting, subaction 2\n",
      "Reading subject 9, action phoning, subaction 1\n",
      "Reading subject 9, action phoning, subaction 2\n",
      "Reading subject 9, action posing, subaction 1\n",
      "Reading subject 9, action posing, subaction 2\n",
      "Reading subject 9, action purchases, subaction 1\n",
      "Reading subject 9, action purchases, subaction 2\n",
      "Reading subject 9, action sitting, subaction 1\n",
      "Reading subject 9, action sitting, subaction 2\n",
      "Reading subject 9, action sittingdown, subaction 1\n",
      "Reading subject 9, action sittingdown, subaction 2\n",
      "Reading subject 9, action takingphoto, subaction 1\n",
      "Reading subject 9, action takingphoto, subaction 2\n",
      "Reading subject 9, action waiting, subaction 1\n",
      "Reading subject 9, action waiting, subaction 2\n",
      "Reading subject 9, action walkingdog, subaction 1\n",
      "Reading subject 9, action walkingdog, subaction 2\n",
      "Reading subject 9, action walkingtogether, subaction 1\n",
      "Reading subject 9, action walkingtogether, subaction 2\n",
      "Reading subject 11, action walking, subaction 1\n",
      "Reading subject 11, action walking, subaction 2\n",
      "Reading subject 11, action eating, subaction 1\n",
      "Reading subject 11, action eating, subaction 2\n",
      "Reading subject 11, action smoking, subaction 1\n",
      "Reading subject 11, action smoking, subaction 2\n",
      "Reading subject 11, action discussion, subaction 1\n",
      "Reading subject 11, action discussion, subaction 2\n",
      "Reading subject 11, action directions, subaction 1\n",
      "Reading subject 11, action directions, subaction 2\n",
      "Reading subject 11, action greeting, subaction 1\n",
      "Reading subject 11, action greeting, subaction 2\n",
      "Reading subject 11, action phoning, subaction 1\n",
      "Reading subject 11, action phoning, subaction 2\n",
      "Reading subject 11, action posing, subaction 1\n",
      "Reading subject 11, action posing, subaction 2\n",
      "Reading subject 11, action purchases, subaction 1\n",
      "Reading subject 11, action purchases, subaction 2\n",
      "Reading subject 11, action sitting, subaction 1\n",
      "Reading subject 11, action sitting, subaction 2\n",
      "Reading subject 11, action sittingdown, subaction 1\n",
      "Reading subject 11, action sittingdown, subaction 2\n",
      "Reading subject 11, action takingphoto, subaction 1\n",
      "Reading subject 11, action takingphoto, subaction 2\n",
      "Reading subject 11, action waiting, subaction 1\n",
      "Reading subject 11, action waiting, subaction 2\n",
      "Reading subject 11, action walkingdog, subaction 1\n",
      "Reading subject 11, action walkingdog, subaction 2\n",
      "Reading subject 11, action walkingtogether, subaction 1\n",
      "Reading subject 11, action walkingtogether, subaction 2\n",
      "Reading subject 5, action walking, subaction 1\n",
      "Reading subject 5, action walking, subaction 2\n",
      "Reading subject 5, action eating, subaction 1\n",
      "Reading subject 5, action eating, subaction 2\n",
      "Reading subject 5, action smoking, subaction 1\n",
      "Reading subject 5, action smoking, subaction 2\n",
      "Reading subject 5, action discussion, subaction 1\n",
      "Reading subject 5, action discussion, subaction 2\n",
      "Reading subject 5, action directions, subaction 1\n",
      "Reading subject 5, action directions, subaction 2\n",
      "Reading subject 5, action greeting, subaction 1\n",
      "Reading subject 5, action greeting, subaction 2\n",
      "Reading subject 5, action phoning, subaction 1\n",
      "Reading subject 5, action phoning, subaction 2\n",
      "Reading subject 5, action posing, subaction 1\n",
      "Reading subject 5, action posing, subaction 2\n",
      "Reading subject 5, action purchases, subaction 1\n",
      "Reading subject 5, action purchases, subaction 2\n",
      "Reading subject 5, action sitting, subaction 1\n",
      "Reading subject 5, action sitting, subaction 2\n",
      "Reading subject 5, action sittingdown, subaction 1\n",
      "Reading subject 5, action sittingdown, subaction 2\n",
      "Reading subject 5, action takingphoto, subaction 1\n",
      "Reading subject 5, action takingphoto, subaction 2\n",
      "Reading subject 5, action waiting, subaction 1\n",
      "Reading subject 5, action waiting, subaction 2\n",
      "Reading subject 5, action walkingdog, subaction 1\n",
      "Reading subject 5, action walkingdog, subaction 2\n",
      "Reading subject 5, action walkingtogether, subaction 1\n",
      "Reading subject 5, action walkingtogether, subaction 2\n",
      "done reading data.\n"
     ]
    }
   ],
   "source": [
    "dloader = DataLoader.DataLoader(50, 25, './data/h3.6m/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before construct network: 0 bytes => 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory usage before construct network: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "                                                   torch.cuda.memory_allocated(device=device)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after construct network: 67533312 bytes => 0.067533312 GB\n"
     ]
    }
   ],
   "source": [
    "lt_encoder = Encoder.Encoder(16,enc_shape=[None, 49, 54, 1], enc_dim_desc={ 'hidden_num': 512,'class_num': 15 }, stride=(2,2))\n",
    "\n",
    "st_encoder = Encoder.Encoder(16,enc_shape=[None, 20, 54, 1], enc_dim_desc={ 'hidden_num': 512}, stride=(2,2))\n",
    "decoder = Decoder.Decoder(st_encoder)\n",
    "\n",
    "generator = ConvSeq2Seq.ConvSeq2Seq(lt_encoder, decoder, window_length=20, device=device)\n",
    "\n",
    "d_encoder = Encoder.Encoder(32, enc_shape=[None, 75,54,1], enc_dim_desc={ 'hidden_num': 512}, stride=(2,2))\n",
    "discriminator = Discriminator.Discriminator(32, d_encoder).to(device)\n",
    "\n",
    "print('Memory usage after construct network: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "                                                   torch.cuda.memory_allocated(device=device)/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.conv1.weight 896\n",
      "encoder.batch_norm1.weight 64\n",
      "encoder.batch_norm1.bias 64\n",
      "encoder.conv2.weight 114688\n",
      "encoder.batch_norm2.weight 128\n",
      "encoder.batch_norm2.bias 128\n",
      "encoder.conv3.weight 229376\n",
      "encoder.batch_norm3.weight 128\n",
      "encoder.batch_norm3.bias 128\n",
      "encoder.fc.weight 3305344\n",
      "encoder.fc.bias 527\n",
      "decoder.st_encoder.conv1.weight 896\n",
      "decoder.st_encoder.batch_norm1.weight 64\n",
      "decoder.st_encoder.batch_norm1.bias 64\n",
      "decoder.st_encoder.conv2.weight 114688\n",
      "decoder.st_encoder.batch_norm2.weight 128\n",
      "decoder.st_encoder.batch_norm2.bias 128\n",
      "decoder.st_encoder.conv3.weight 229376\n",
      "decoder.st_encoder.batch_norm3.weight 128\n",
      "decoder.st_encoder.batch_norm3.bias 128\n",
      "decoder.st_encoder.fc.weight 1376256\n",
      "decoder.st_encoder.fc.bias 512\n",
      "decoder.fc1.weight 524288\n",
      "decoder.fc1.bias 512\n",
      "decoder.fc2.weight 27648\n",
      "decoder.fc2.bias 54\n"
     ]
    }
   ],
   "source": [
    "for name, param in generator.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_encoder.conv1.weight 1792\n",
      "d_encoder.batch_norm1.weight 128\n",
      "d_encoder.batch_norm1.bias 128\n",
      "d_encoder.conv2.weight 458752\n",
      "d_encoder.batch_norm2.weight 256\n",
      "d_encoder.batch_norm2.bias 256\n",
      "d_encoder.conv3.weight 917504\n",
      "d_encoder.batch_norm3.weight 256\n",
      "d_encoder.batch_norm3.bias 256\n",
      "d_encoder.fc.weight 9175040\n",
      "d_encoder.fc.bias 512\n",
      "fc1.weight 134912\n",
      "fc1.bias 256\n",
      "fc2.weight 256\n",
      "fc2.bias 1\n"
     ]
    }
   ],
   "source": [
    "for name, param in discriminator.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    lt_encoder = Encoder.Encoder(16,enc_shape=[None, 49, 54, 1], \n",
    "                                 enc_dim_desc={ 'hidden_num': 512,'class_num': 15 }, \n",
    "                                 stride=(2,2), \n",
    "                                 kernel_size=(2, 7))\n",
    "\n",
    "    st_encoder = Encoder.Encoder(16,enc_shape=[None, 20, 54, 1], \n",
    "                                 enc_dim_desc={ 'hidden_num': 512}, \n",
    "                                 stride=(2,2), \n",
    "                                 kernel_size=(2, 7))\n",
    "    decoder = Decoder.Decoder(st_encoder)\n",
    "\n",
    "    generator = ConvSeq2Seq.ConvSeq2Seq(lt_encoder, decoder, window_length=20, device=device)\n",
    "\n",
    "    d_encoder = Encoder.Encoder(32, enc_shape=[None, 75,54,1], \n",
    "                                enc_dim_desc={ 'hidden_num': 512}, \n",
    "                                stride=(2,2), \n",
    "                                kernel_size=(2, 7))\n",
    "    discriminator = Discriminator.Discriminator(32, d_encoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 0 loss_d 1.387010, loss_g 0.276363, lr 0.000050, time 0.867337\n",
      "Iterations 100 loss_d 1.374417, loss_g 0.248493, lr 0.000050, time 64.358381\n",
      "Iterations 200 loss_d 1.255111, loss_g 0.232910, lr 0.000050, time 126.736285\n",
      "Iterations 300 loss_d 1.155149, loss_g 0.227703, lr 0.000050, time 188.517448\n",
      "Iterations 400 loss_d 1.085928, loss_g 0.209014, lr 0.000050, time 249.691169\n",
      "Iterations 500 loss_d 1.100226, loss_g 0.224744, lr 0.000050, time 308.562355\n",
      "Iterations 600 loss_d 1.012678, loss_g 0.213151, lr 0.000050, time 370.601089\n",
      "Iterations 700 loss_d 1.015243, loss_g 0.200227, lr 0.000050, time 433.138354\n",
      "Iterations 800 loss_d 0.983804, loss_g 0.209434, lr 0.000050, time 496.688075\n",
      "Iterations 900 loss_d 0.987851, loss_g 0.212384, lr 0.000050, time 561.508905\n",
      "Iterations 1000 loss_d 0.948644, loss_g 0.206390, lr 0.000050, time 624.843547\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1138/1846950332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m util.train(dloader, \n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mG_criterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mD_criterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/CS7643_DL/Project/util.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dloader, generator, discriminator, G_criterion, D_criterion, optimizerG, optimizerD, device, batch, lr, lr_decay_steps, lr_decay, L2_lambda, iterations, display, model_name)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mReconstructError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mReconstructError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0md_logits_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv-seq2seq-torch-gpu/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/conv-seq2seq-torch-gpu/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "util.train(dloader, \n",
    "           generator, \n",
    "           discriminator, \n",
    "           device=device,\n",
    "           batch = 16,\n",
    "           lr=5e-5,\n",
    "           lr_decay_steps = 10000,\n",
    "           lr_decay = 0.99,\n",
    "           L2_lambda = 0.001,\n",
    "           iterations = 1000,\n",
    "           display = 100,\n",
    "           tensorboard=True,\n",
    "           save_model=True,\n",
    "           model_name='default_setting_1000_itr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading subject 1, action walking, subaction 1\n",
      "Reading subject 1, action walking, subaction 2\n",
      "Reading subject 1, action eating, subaction 1\n",
      "Reading subject 1, action eating, subaction 2\n",
      "Reading subject 1, action smoking, subaction 1\n",
      "Reading subject 1, action smoking, subaction 2\n",
      "Reading subject 1, action discussion, subaction 1\n",
      "Reading subject 1, action discussion, subaction 2\n",
      "Reading subject 1, action directions, subaction 1\n",
      "Reading subject 1, action directions, subaction 2\n",
      "Reading subject 1, action greeting, subaction 1\n",
      "Reading subject 1, action greeting, subaction 2\n",
      "Reading subject 1, action phoning, subaction 1\n",
      "Reading subject 1, action phoning, subaction 2\n",
      "Reading subject 1, action posing, subaction 1\n",
      "Reading subject 1, action posing, subaction 2\n",
      "Reading subject 1, action purchases, subaction 1\n",
      "Reading subject 1, action purchases, subaction 2\n",
      "Reading subject 1, action sitting, subaction 1\n",
      "Reading subject 1, action sitting, subaction 2\n",
      "Reading subject 1, action sittingdown, subaction 1\n",
      "Reading subject 1, action sittingdown, subaction 2\n",
      "Reading subject 1, action takingphoto, subaction 1\n",
      "Reading subject 1, action takingphoto, subaction 2\n",
      "Reading subject 1, action waiting, subaction 1\n",
      "Reading subject 1, action waiting, subaction 2\n",
      "Reading subject 1, action walkingdog, subaction 1\n",
      "Reading subject 1, action walkingdog, subaction 2\n",
      "Reading subject 1, action walkingtogether, subaction 1\n",
      "Reading subject 1, action walkingtogether, subaction 2\n",
      "Reading subject 6, action walking, subaction 1\n",
      "Reading subject 6, action walking, subaction 2\n",
      "Reading subject 6, action eating, subaction 1\n",
      "Reading subject 6, action eating, subaction 2\n",
      "Reading subject 6, action smoking, subaction 1\n",
      "Reading subject 6, action smoking, subaction 2\n",
      "Reading subject 6, action discussion, subaction 1\n",
      "Reading subject 6, action discussion, subaction 2\n",
      "Reading subject 6, action directions, subaction 1\n",
      "Reading subject 6, action directions, subaction 2\n",
      "Reading subject 6, action greeting, subaction 1\n",
      "Reading subject 6, action greeting, subaction 2\n",
      "Reading subject 6, action phoning, subaction 1\n",
      "Reading subject 6, action phoning, subaction 2\n",
      "Reading subject 6, action posing, subaction 1\n",
      "Reading subject 6, action posing, subaction 2\n",
      "Reading subject 6, action purchases, subaction 1\n",
      "Reading subject 6, action purchases, subaction 2\n",
      "Reading subject 6, action sitting, subaction 1\n",
      "Reading subject 6, action sitting, subaction 2\n",
      "Reading subject 6, action sittingdown, subaction 1\n",
      "Reading subject 6, action sittingdown, subaction 2\n",
      "Reading subject 6, action takingphoto, subaction 1\n",
      "Reading subject 6, action takingphoto, subaction 2\n",
      "Reading subject 6, action waiting, subaction 1\n",
      "Reading subject 6, action waiting, subaction 2\n",
      "Reading subject 6, action walkingdog, subaction 1\n",
      "Reading subject 6, action walkingdog, subaction 2\n",
      "Reading subject 6, action walkingtogether, subaction 1\n",
      "Reading subject 6, action walkingtogether, subaction 2\n",
      "Reading subject 7, action walking, subaction 1\n",
      "Reading subject 7, action walking, subaction 2\n",
      "Reading subject 7, action eating, subaction 1\n",
      "Reading subject 7, action eating, subaction 2\n",
      "Reading subject 7, action smoking, subaction 1\n",
      "Reading subject 7, action smoking, subaction 2\n",
      "Reading subject 7, action discussion, subaction 1\n",
      "Reading subject 7, action discussion, subaction 2\n",
      "Reading subject 7, action directions, subaction 1\n",
      "Reading subject 7, action directions, subaction 2\n",
      "Reading subject 7, action greeting, subaction 1\n",
      "Reading subject 7, action greeting, subaction 2\n",
      "Reading subject 7, action phoning, subaction 1\n",
      "Reading subject 7, action phoning, subaction 2\n",
      "Reading subject 7, action posing, subaction 1\n",
      "Reading subject 7, action posing, subaction 2\n",
      "Reading subject 7, action purchases, subaction 1\n",
      "Reading subject 7, action purchases, subaction 2\n",
      "Reading subject 7, action sitting, subaction 1\n",
      "Reading subject 7, action sitting, subaction 2\n",
      "Reading subject 7, action sittingdown, subaction 1\n",
      "Reading subject 7, action sittingdown, subaction 2\n",
      "Reading subject 7, action takingphoto, subaction 1\n",
      "Reading subject 7, action takingphoto, subaction 2\n",
      "Reading subject 7, action waiting, subaction 1\n",
      "Reading subject 7, action waiting, subaction 2\n",
      "Reading subject 7, action walkingdog, subaction 1\n",
      "Reading subject 7, action walkingdog, subaction 2\n",
      "Reading subject 7, action walkingtogether, subaction 1\n",
      "Reading subject 7, action walkingtogether, subaction 2\n",
      "Reading subject 8, action walking, subaction 1\n",
      "Reading subject 8, action walking, subaction 2\n",
      "Reading subject 8, action eating, subaction 1\n",
      "Reading subject 8, action eating, subaction 2\n",
      "Reading subject 8, action smoking, subaction 1\n",
      "Reading subject 8, action smoking, subaction 2\n",
      "Reading subject 8, action discussion, subaction 1\n",
      "Reading subject 8, action discussion, subaction 2\n",
      "Reading subject 8, action directions, subaction 1\n",
      "Reading subject 8, action directions, subaction 2\n",
      "Reading subject 8, action greeting, subaction 1\n",
      "Reading subject 8, action greeting, subaction 2\n",
      "Reading subject 8, action phoning, subaction 1\n",
      "Reading subject 8, action phoning, subaction 2\n",
      "Reading subject 8, action posing, subaction 1\n",
      "Reading subject 8, action posing, subaction 2\n",
      "Reading subject 8, action purchases, subaction 1\n",
      "Reading subject 8, action purchases, subaction 2\n",
      "Reading subject 8, action sitting, subaction 1\n",
      "Reading subject 8, action sitting, subaction 2\n",
      "Reading subject 8, action sittingdown, subaction 1\n",
      "Reading subject 8, action sittingdown, subaction 2\n",
      "Reading subject 8, action takingphoto, subaction 1\n",
      "Reading subject 8, action takingphoto, subaction 2\n",
      "Reading subject 8, action waiting, subaction 1\n",
      "Reading subject 8, action waiting, subaction 2\n",
      "Reading subject 8, action walkingdog, subaction 1\n",
      "Reading subject 8, action walkingdog, subaction 2\n",
      "Reading subject 8, action walkingtogether, subaction 1\n",
      "Reading subject 8, action walkingtogether, subaction 2\n",
      "Reading subject 9, action walking, subaction 1\n",
      "Reading subject 9, action walking, subaction 2\n",
      "Reading subject 9, action eating, subaction 1\n",
      "Reading subject 9, action eating, subaction 2\n",
      "Reading subject 9, action smoking, subaction 1\n",
      "Reading subject 9, action smoking, subaction 2\n",
      "Reading subject 9, action discussion, subaction 1\n",
      "Reading subject 9, action discussion, subaction 2\n",
      "Reading subject 9, action directions, subaction 1\n",
      "Reading subject 9, action directions, subaction 2\n",
      "Reading subject 9, action greeting, subaction 1\n",
      "Reading subject 9, action greeting, subaction 2\n",
      "Reading subject 9, action phoning, subaction 1\n",
      "Reading subject 9, action phoning, subaction 2\n",
      "Reading subject 9, action posing, subaction 1\n",
      "Reading subject 9, action posing, subaction 2\n",
      "Reading subject 9, action purchases, subaction 1\n",
      "Reading subject 9, action purchases, subaction 2\n",
      "Reading subject 9, action sitting, subaction 1\n",
      "Reading subject 9, action sitting, subaction 2\n",
      "Reading subject 9, action sittingdown, subaction 1\n",
      "Reading subject 9, action sittingdown, subaction 2\n",
      "Reading subject 9, action takingphoto, subaction 1\n",
      "Reading subject 9, action takingphoto, subaction 2\n",
      "Reading subject 9, action waiting, subaction 1\n",
      "Reading subject 9, action waiting, subaction 2\n",
      "Reading subject 9, action walkingdog, subaction 1\n",
      "Reading subject 9, action walkingdog, subaction 2\n",
      "Reading subject 9, action walkingtogether, subaction 1\n",
      "Reading subject 9, action walkingtogether, subaction 2\n",
      "Reading subject 11, action walking, subaction 1\n",
      "Reading subject 11, action walking, subaction 2\n",
      "Reading subject 11, action eating, subaction 1\n",
      "Reading subject 11, action eating, subaction 2\n",
      "Reading subject 11, action smoking, subaction 1\n",
      "Reading subject 11, action smoking, subaction 2\n",
      "Reading subject 11, action discussion, subaction 1\n",
      "Reading subject 11, action discussion, subaction 2\n",
      "Reading subject 11, action directions, subaction 1\n",
      "Reading subject 11, action directions, subaction 2\n",
      "Reading subject 11, action greeting, subaction 1\n",
      "Reading subject 11, action greeting, subaction 2\n",
      "Reading subject 11, action phoning, subaction 1\n",
      "Reading subject 11, action phoning, subaction 2\n",
      "Reading subject 11, action posing, subaction 1\n",
      "Reading subject 11, action posing, subaction 2\n",
      "Reading subject 11, action purchases, subaction 1\n",
      "Reading subject 11, action purchases, subaction 2\n",
      "Reading subject 11, action sitting, subaction 1\n",
      "Reading subject 11, action sitting, subaction 2\n",
      "Reading subject 11, action sittingdown, subaction 1\n",
      "Reading subject 11, action sittingdown, subaction 2\n",
      "Reading subject 11, action takingphoto, subaction 1\n",
      "Reading subject 11, action takingphoto, subaction 2\n",
      "Reading subject 11, action waiting, subaction 1\n",
      "Reading subject 11, action waiting, subaction 2\n",
      "Reading subject 11, action walkingdog, subaction 1\n",
      "Reading subject 11, action walkingdog, subaction 2\n",
      "Reading subject 11, action walkingtogether, subaction 1\n",
      "Reading subject 11, action walkingtogether, subaction 2\n",
      "Reading subject 5, action walking, subaction 1\n",
      "Reading subject 5, action walking, subaction 2\n",
      "Reading subject 5, action eating, subaction 1\n",
      "Reading subject 5, action eating, subaction 2\n",
      "Reading subject 5, action smoking, subaction 1\n",
      "Reading subject 5, action smoking, subaction 2\n",
      "Reading subject 5, action discussion, subaction 1\n",
      "Reading subject 5, action discussion, subaction 2\n",
      "Reading subject 5, action directions, subaction 1\n",
      "Reading subject 5, action directions, subaction 2\n",
      "Reading subject 5, action greeting, subaction 1\n",
      "Reading subject 5, action greeting, subaction 2\n",
      "Reading subject 5, action phoning, subaction 1\n",
      "Reading subject 5, action phoning, subaction 2\n",
      "Reading subject 5, action posing, subaction 1\n",
      "Reading subject 5, action posing, subaction 2\n",
      "Reading subject 5, action purchases, subaction 1\n",
      "Reading subject 5, action purchases, subaction 2\n",
      "Reading subject 5, action sitting, subaction 1\n",
      "Reading subject 5, action sitting, subaction 2\n",
      "Reading subject 5, action sittingdown, subaction 1\n",
      "Reading subject 5, action sittingdown, subaction 2\n",
      "Reading subject 5, action takingphoto, subaction 1\n",
      "Reading subject 5, action takingphoto, subaction 2\n",
      "Reading subject 5, action waiting, subaction 1\n",
      "Reading subject 5, action waiting, subaction 2\n",
      "Reading subject 5, action walkingdog, subaction 1\n",
      "Reading subject 5, action walkingdog, subaction 2\n",
      "Reading subject 5, action walkingtogether, subaction 1\n",
      "Reading subject 5, action walkingtogether, subaction 2\n",
      "done reading data.\n"
     ]
    }
   ],
   "source": [
    "dloader = DataLoader.DataLoader(50, 25, './data/h3.6m/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Using device: cuda\n",
      "Training on following parameters: \n",
      "lr=0.00005000\n",
      "L2_lambda=0.00\n",
      "lt_encoder_filters size=16.00\n",
      "st_encoder_filters size=16.00\n",
      "d_encoder_filters size=32.00\n",
      "discriminator_output_filters size=32.00\n",
      "kernel size=(9,6)\n",
      "stride=(2,2)\n",
      "Iterations 0 loss_d 1.387902, loss_g 0.273694, lr 0.000050, time 2.554062\n",
      "Iterations 100 loss_d 1.358522, loss_g 0.224902, lr 0.000050, time 252.704688\n",
      "Iterations 200 loss_d 1.097444, loss_g 0.229988, lr 0.000050, time 508.124125\n",
      "Iterations 300 loss_d 0.829321, loss_g 0.230110, lr 0.000050, time 777.423306\n",
      "Iterations 400 loss_d 0.629069, loss_g 0.222812, lr 0.000050, time 1048.998810\n",
      "Iterations 500 loss_d 0.596275, loss_g 0.232395, lr 0.000050, time 1322.922085\n",
      "Iterations 600 loss_d 0.512243, loss_g 0.226099, lr 0.000050, time 1581.479376\n",
      "Iterations 700 loss_d 0.510012, loss_g 0.218592, lr 0.000050, time 1823.992167\n",
      "Iterations 800 loss_d 0.456715, loss_g 0.213946, lr 0.000050, time 2044.261043\n",
      "Iterations 900 loss_d 0.520800, loss_g 0.223337, lr 0.000050, time 2282.446213\n",
      "Test error=325.38647                                  \n",
      "============================================================                        \n",
      "Using device: cuda\n",
      "Training on following parameters: \n",
      "lr=0.00005000\n",
      "L2_lambda=0.00\n",
      "lt_encoder_filters size=16.00\n",
      "st_encoder_filters size=16.00\n",
      "d_encoder_filters size=32.00\n",
      "discriminator_output_filters size=32.00\n",
      "kernel size=(10,10)\n",
      "stride=(2,2)\n",
      "Iterations 0 loss_d 1.386497, loss_g 0.205583, lr 0.000050, time 4.420542           \n",
      "Iterations 100 loss_d 1.354125, loss_g 0.235727, lr 0.000050, time 454.071809       \n",
      "Iterations 200 loss_d 1.153709, loss_g 0.223645, lr 0.000050, time 926.130330       \n",
      "Iterations 300 loss_d 0.841246, loss_g 0.226788, lr 0.000050, time 1363.769022      \n",
      "Iterations 400 loss_d 0.753859, loss_g 0.234178, lr 0.000050, time 1838.732566        \n",
      "Iterations 500 loss_d 0.632320, loss_g 0.224020, lr 0.000050, time 2312.852085        \n",
      "Iterations 600 loss_d 0.603602, loss_g 0.211436, lr 0.000050, time 2759.699009        \n",
      "Iterations 700 loss_d 0.554681, loss_g 0.208853, lr 0.000050, time 3159.772786        \n",
      "Iterations 800 loss_d 0.557101, loss_g 0.220174, lr 0.000050, time 3604.060232        \n",
      "Iterations 900 loss_d 0.540717, loss_g 0.204376, lr 0.000050, time 4048.793722        \n",
      "Test error=331.44966                                                                  \n",
      "============================================================                          \n",
      "Using device: cuda\n",
      "Training on following parameters: \n",
      "lr=0.00005000\n",
      "L2_lambda=0.00\n",
      "lt_encoder_filters size=16.00\n",
      "st_encoder_filters size=16.00\n",
      "d_encoder_filters size=32.00\n",
      "discriminator_output_filters size=32.00\n",
      "kernel size=(3,14)\n",
      "stride=(2,2)\n",
      "Iterations 0 loss_d 1.385465, loss_g 0.262065, lr 0.000050, time 3.094587             \n",
      "  4%|‚ñç         | 2/50 [1:57:27<49:16:45, 3695.95s/trial, best loss: 325.3864706286695]"
     ]
    }
   ],
   "source": [
    "space = {'lr': 5e-5,\n",
    "         'L2_lambda': 0.001,\n",
    "         'lt_encoder_filters': 16,\n",
    "         'st_encoder_filters': 16,\n",
    "         'd_encoder_filters': 32,\n",
    "         'discriminator_output_filters': 32,\n",
    "         'kernel_height': scope.int(hp.quniform('kernel_height',2,10,1)),\n",
    "         'kernel_width': scope.int(hp.quniform('kernel_width',5,20,2)),\n",
    "         'stride_vert': 2,\n",
    "         'stride_hori': 2,\n",
    "         'device': device\n",
    "}\n",
    "\n",
    "# space = {'lr': hp.uniform('lr', 0.000001, 0.01),\n",
    "#          'L2_lambda': hp.uniform('L2_lambda', 0.001, 0.1),\n",
    "#          'lt_encoder_filters': scope.int(hp.quniform('lt_encoder_filters',4,64,4)),\n",
    "#          'st_encoder_filters': scope.int(hp.quniform('st_encoder_filters',4,64,4)),\n",
    "#          'd_encoder_filters': scope.int(hp.quniform('d_encoder_filters',4,64,4)),\n",
    "#          'discriminator_output_filters': scope.int(hp.quniform('discriminator_output_filters',4,64,4)),\n",
    "#          'kernel_height': scope.int(hp.quniform('kernel_height',2,10,1)),\n",
    "#          'kernel_width': scope.int(hp.quniform('kernel_width',5,20,2)),\n",
    "#          'stride_vert': scope.int(hp.quniform('stride_vert',1,5,1)),\n",
    "#          'stride_hori': scope.int(hp.quniform('stride_hori',2,5,1)),\n",
    "#          'device': device\n",
    "# }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(partial(util.optimize, dloader), \n",
    "            space, \n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "pickle.dump(trials, open(\"{}/trial_{}.pkl\".format('tuning_save_dir', 0), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading subject 1, action walking, subaction 1\n",
      "Reading subject 1, action walking, subaction 2\n",
      "Reading subject 1, action eating, subaction 1\n",
      "Reading subject 1, action eating, subaction 2\n",
      "Reading subject 1, action smoking, subaction 1\n",
      "Reading subject 1, action smoking, subaction 2\n",
      "Reading subject 1, action discussion, subaction 1\n",
      "Reading subject 1, action discussion, subaction 2\n",
      "Reading subject 1, action directions, subaction 1\n",
      "Reading subject 1, action directions, subaction 2\n",
      "Reading subject 1, action greeting, subaction 1\n",
      "Reading subject 1, action greeting, subaction 2\n",
      "Reading subject 1, action phoning, subaction 1\n",
      "Reading subject 1, action phoning, subaction 2\n",
      "Reading subject 1, action posing, subaction 1\n",
      "Reading subject 1, action posing, subaction 2\n",
      "Reading subject 1, action purchases, subaction 1\n",
      "Reading subject 1, action purchases, subaction 2\n",
      "Reading subject 1, action sitting, subaction 1\n",
      "Reading subject 1, action sitting, subaction 2\n",
      "Reading subject 1, action sittingdown, subaction 1\n",
      "Reading subject 1, action sittingdown, subaction 2\n",
      "Reading subject 1, action takingphoto, subaction 1\n",
      "Reading subject 1, action takingphoto, subaction 2\n",
      "Reading subject 1, action waiting, subaction 1\n",
      "Reading subject 1, action waiting, subaction 2\n",
      "Reading subject 1, action walkingdog, subaction 1\n",
      "Reading subject 1, action walkingdog, subaction 2\n",
      "Reading subject 1, action walkingtogether, subaction 1\n",
      "Reading subject 1, action walkingtogether, subaction 2\n",
      "Reading subject 6, action walking, subaction 1\n",
      "Reading subject 6, action walking, subaction 2\n",
      "Reading subject 6, action eating, subaction 1\n",
      "Reading subject 6, action eating, subaction 2\n",
      "Reading subject 6, action smoking, subaction 1\n",
      "Reading subject 6, action smoking, subaction 2\n",
      "Reading subject 6, action discussion, subaction 1\n",
      "Reading subject 6, action discussion, subaction 2\n",
      "Reading subject 6, action directions, subaction 1\n",
      "Reading subject 6, action directions, subaction 2\n",
      "Reading subject 6, action greeting, subaction 1\n",
      "Reading subject 6, action greeting, subaction 2\n",
      "Reading subject 6, action phoning, subaction 1\n",
      "Reading subject 6, action phoning, subaction 2\n",
      "Reading subject 6, action posing, subaction 1\n",
      "Reading subject 6, action posing, subaction 2\n",
      "Reading subject 6, action purchases, subaction 1\n",
      "Reading subject 6, action purchases, subaction 2\n",
      "Reading subject 6, action sitting, subaction 1\n",
      "Reading subject 6, action sitting, subaction 2\n",
      "Reading subject 6, action sittingdown, subaction 1\n",
      "Reading subject 6, action sittingdown, subaction 2\n",
      "Reading subject 6, action takingphoto, subaction 1\n",
      "Reading subject 6, action takingphoto, subaction 2\n",
      "Reading subject 6, action waiting, subaction 1\n",
      "Reading subject 6, action waiting, subaction 2\n",
      "Reading subject 6, action walkingdog, subaction 1\n",
      "Reading subject 6, action walkingdog, subaction 2\n",
      "Reading subject 6, action walkingtogether, subaction 1\n",
      "Reading subject 6, action walkingtogether, subaction 2\n",
      "Reading subject 7, action walking, subaction 1\n",
      "Reading subject 7, action walking, subaction 2\n",
      "Reading subject 7, action eating, subaction 1\n",
      "Reading subject 7, action eating, subaction 2\n",
      "Reading subject 7, action smoking, subaction 1\n",
      "Reading subject 7, action smoking, subaction 2\n",
      "Reading subject 7, action discussion, subaction 1\n",
      "Reading subject 7, action discussion, subaction 2\n",
      "Reading subject 7, action directions, subaction 1\n",
      "Reading subject 7, action directions, subaction 2\n",
      "Reading subject 7, action greeting, subaction 1\n",
      "Reading subject 7, action greeting, subaction 2\n",
      "Reading subject 7, action phoning, subaction 1\n",
      "Reading subject 7, action phoning, subaction 2\n",
      "Reading subject 7, action posing, subaction 1\n",
      "Reading subject 7, action posing, subaction 2\n",
      "Reading subject 7, action purchases, subaction 1\n",
      "Reading subject 7, action purchases, subaction 2\n",
      "Reading subject 7, action sitting, subaction 1\n",
      "Reading subject 7, action sitting, subaction 2\n",
      "Reading subject 7, action sittingdown, subaction 1\n",
      "Reading subject 7, action sittingdown, subaction 2\n",
      "Reading subject 7, action takingphoto, subaction 1\n",
      "Reading subject 7, action takingphoto, subaction 2\n",
      "Reading subject 7, action waiting, subaction 1\n",
      "Reading subject 7, action waiting, subaction 2\n",
      "Reading subject 7, action walkingdog, subaction 1\n",
      "Reading subject 7, action walkingdog, subaction 2\n",
      "Reading subject 7, action walkingtogether, subaction 1\n",
      "Reading subject 7, action walkingtogether, subaction 2\n",
      "Reading subject 8, action walking, subaction 1\n",
      "Reading subject 8, action walking, subaction 2\n",
      "Reading subject 8, action eating, subaction 1\n",
      "Reading subject 8, action eating, subaction 2\n",
      "Reading subject 8, action smoking, subaction 1\n",
      "Reading subject 8, action smoking, subaction 2\n",
      "Reading subject 8, action discussion, subaction 1\n",
      "Reading subject 8, action discussion, subaction 2\n",
      "Reading subject 8, action directions, subaction 1\n",
      "Reading subject 8, action directions, subaction 2\n",
      "Reading subject 8, action greeting, subaction 1\n",
      "Reading subject 8, action greeting, subaction 2\n",
      "Reading subject 8, action phoning, subaction 1\n",
      "Reading subject 8, action phoning, subaction 2\n",
      "Reading subject 8, action posing, subaction 1\n",
      "Reading subject 8, action posing, subaction 2\n",
      "Reading subject 8, action purchases, subaction 1\n",
      "Reading subject 8, action purchases, subaction 2\n",
      "Reading subject 8, action sitting, subaction 1\n",
      "Reading subject 8, action sitting, subaction 2\n",
      "Reading subject 8, action sittingdown, subaction 1\n",
      "Reading subject 8, action sittingdown, subaction 2\n",
      "Reading subject 8, action takingphoto, subaction 1\n",
      "Reading subject 8, action takingphoto, subaction 2\n",
      "Reading subject 8, action waiting, subaction 1\n",
      "Reading subject 8, action waiting, subaction 2\n",
      "Reading subject 8, action walkingdog, subaction 1\n",
      "Reading subject 8, action walkingdog, subaction 2\n",
      "Reading subject 8, action walkingtogether, subaction 1\n",
      "Reading subject 8, action walkingtogether, subaction 2\n",
      "Reading subject 9, action walking, subaction 1\n",
      "Reading subject 9, action walking, subaction 2\n",
      "Reading subject 9, action eating, subaction 1\n",
      "Reading subject 9, action eating, subaction 2\n",
      "Reading subject 9, action smoking, subaction 1\n",
      "Reading subject 9, action smoking, subaction 2\n",
      "Reading subject 9, action discussion, subaction 1\n",
      "Reading subject 9, action discussion, subaction 2\n",
      "Reading subject 9, action directions, subaction 1\n",
      "Reading subject 9, action directions, subaction 2\n",
      "Reading subject 9, action greeting, subaction 1\n",
      "Reading subject 9, action greeting, subaction 2\n",
      "Reading subject 9, action phoning, subaction 1\n",
      "Reading subject 9, action phoning, subaction 2\n",
      "Reading subject 9, action posing, subaction 1\n",
      "Reading subject 9, action posing, subaction 2\n",
      "Reading subject 9, action purchases, subaction 1\n",
      "Reading subject 9, action purchases, subaction 2\n",
      "Reading subject 9, action sitting, subaction 1\n",
      "Reading subject 9, action sitting, subaction 2\n",
      "Reading subject 9, action sittingdown, subaction 1\n",
      "Reading subject 9, action sittingdown, subaction 2\n",
      "Reading subject 9, action takingphoto, subaction 1\n",
      "Reading subject 9, action takingphoto, subaction 2\n",
      "Reading subject 9, action waiting, subaction 1\n",
      "Reading subject 9, action waiting, subaction 2\n",
      "Reading subject 9, action walkingdog, subaction 1\n",
      "Reading subject 9, action walkingdog, subaction 2\n",
      "Reading subject 9, action walkingtogether, subaction 1\n",
      "Reading subject 9, action walkingtogether, subaction 2\n",
      "Reading subject 11, action walking, subaction 1\n",
      "Reading subject 11, action walking, subaction 2\n",
      "Reading subject 11, action eating, subaction 1\n",
      "Reading subject 11, action eating, subaction 2\n",
      "Reading subject 11, action smoking, subaction 1\n",
      "Reading subject 11, action smoking, subaction 2\n",
      "Reading subject 11, action discussion, subaction 1\n",
      "Reading subject 11, action discussion, subaction 2\n",
      "Reading subject 11, action directions, subaction 1\n",
      "Reading subject 11, action directions, subaction 2\n",
      "Reading subject 11, action greeting, subaction 1\n",
      "Reading subject 11, action greeting, subaction 2\n",
      "Reading subject 11, action phoning, subaction 1\n",
      "Reading subject 11, action phoning, subaction 2\n",
      "Reading subject 11, action posing, subaction 1\n",
      "Reading subject 11, action posing, subaction 2\n",
      "Reading subject 11, action purchases, subaction 1\n",
      "Reading subject 11, action purchases, subaction 2\n",
      "Reading subject 11, action sitting, subaction 1\n",
      "Reading subject 11, action sitting, subaction 2\n",
      "Reading subject 11, action sittingdown, subaction 1\n",
      "Reading subject 11, action sittingdown, subaction 2\n",
      "Reading subject 11, action takingphoto, subaction 1\n",
      "Reading subject 11, action takingphoto, subaction 2\n",
      "Reading subject 11, action waiting, subaction 1\n",
      "Reading subject 11, action waiting, subaction 2\n",
      "Reading subject 11, action walkingdog, subaction 1\n",
      "Reading subject 11, action walkingdog, subaction 2\n",
      "Reading subject 11, action walkingtogether, subaction 1\n",
      "Reading subject 11, action walkingtogether, subaction 2\n",
      "Reading subject 5, action walking, subaction 1\n",
      "Reading subject 5, action walking, subaction 2\n",
      "Reading subject 5, action eating, subaction 1\n",
      "Reading subject 5, action eating, subaction 2\n",
      "Reading subject 5, action smoking, subaction 1\n",
      "Reading subject 5, action smoking, subaction 2\n",
      "Reading subject 5, action discussion, subaction 1\n",
      "Reading subject 5, action discussion, subaction 2\n",
      "Reading subject 5, action directions, subaction 1\n",
      "Reading subject 5, action directions, subaction 2\n",
      "Reading subject 5, action greeting, subaction 1\n",
      "Reading subject 5, action greeting, subaction 2\n",
      "Reading subject 5, action phoning, subaction 1\n",
      "Reading subject 5, action phoning, subaction 2\n",
      "Reading subject 5, action posing, subaction 1\n",
      "Reading subject 5, action posing, subaction 2\n",
      "Reading subject 5, action purchases, subaction 1\n",
      "Reading subject 5, action purchases, subaction 2\n",
      "Reading subject 5, action sitting, subaction 1\n",
      "Reading subject 5, action sitting, subaction 2\n",
      "Reading subject 5, action sittingdown, subaction 1\n",
      "Reading subject 5, action sittingdown, subaction 2\n",
      "Reading subject 5, action takingphoto, subaction 1\n",
      "Reading subject 5, action takingphoto, subaction 2\n",
      "Reading subject 5, action waiting, subaction 1\n",
      "Reading subject 5, action waiting, subaction 2\n",
      "Reading subject 5, action walkingdog, subaction 1\n",
      "Reading subject 5, action walkingdog, subaction 2\n",
      "Reading subject 5, action walkingtogether, subaction 1\n",
      "Reading subject 5, action walkingtogether, subaction 2\n",
      "done reading data.\n"
     ]
    }
   ],
   "source": [
    "dloader = DataLoader.DataLoader(50, 25, './data/h3.6m/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "walking\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "walking          | 0.323 | 0.509 | 0.638 | 0.669 | 0.658 | 0.630 |\n",
      "\n",
      "eating\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "eating           | 0.232 | 0.354 | 0.497 | 0.586 | 0.641 | 0.805 |\n",
      "\n",
      "smoking\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "smoking          | 0.245 | 0.424 | 0.766 | 0.704 | 0.668 | 1.038 |\n",
      "\n",
      "discussion\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "discussion       | 0.282 | 0.572 | 0.707 | 0.749 | 1.066 | 1.119 |\n",
      "\n",
      "directions\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "directions       | 0.384 | 0.542 | 0.638 | 0.680 | 0.685 | 0.818 |\n",
      "\n",
      "greeting\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "greeting         | 0.506 | 0.776 | 1.026 | 1.121 | 1.230 | 1.047 |\n",
      "\n",
      "phoning\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "phoning          | 0.594 | 1.077 | 1.334 | 1.414 | 1.105 | 1.050 |\n",
      "\n",
      "posing\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "posing           | 0.403 | 0.690 | 1.116 | 1.268 | 1.442 | 1.484 |\n",
      "\n",
      "purchases\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "purchases        | 0.579 | 0.752 | 0.959 | 0.938 | 1.177 | 1.681 |\n",
      "\n",
      "sitting\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "sitting          | 0.381 | 0.562 | 0.826 | 0.925 | 0.903 | 1.210 |\n",
      "\n",
      "sittingdown\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "sittingdown      | 0.397 | 0.685 | 0.899 | 0.950 | 0.991 | 1.126 |\n",
      "\n",
      "takingphoto\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "takingphoto      | 0.239 | 0.464 | 0.640 | 0.709 | 0.745 | 0.715 |\n",
      "\n",
      "waiting\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "waiting          | 0.317 | 0.598 | 0.955 | 1.086 | 1.266 | 1.408 |\n",
      "\n",
      "walkingdog\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "walkingdog       | 0.534 | 0.808 | 1.022 | 1.103 | 1.251 | 1.219 |\n",
      "\n",
      "walkingtogether\n",
      "\n",
      "milliseconds     |    80 |   160 |   320 |   400 |   560 |  1000 |\n",
      "walkingtogether  | 0.295 | 0.550 | 0.671 | 0.662 | 0.682 | 1.008 |\n",
      "0.10004779999996269\n"
     ]
    }
   ],
   "source": [
    "util.InferenceSample(dloader, generator, model_name='default_setting_1000_itr', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grave Yard **********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20000]\tLoss_D: 1.3884\tLoss_G: 0.2619\n",
      "[100/20000]\tLoss_D: 1.2983\tLoss_G: 0.2432\n",
      "[200/20000]\tLoss_D: 1.1957\tLoss_G: 0.2439\n",
      "[300/20000]\tLoss_D: 0.9976\tLoss_G: 0.3253\n",
      "[400/20000]\tLoss_D: 1.1649\tLoss_G: 0.1919\n",
      "[500/20000]\tLoss_D: 1.1214\tLoss_G: 0.2258\n",
      "[600/20000]\tLoss_D: 1.0522\tLoss_G: 0.3107\n",
      "[700/20000]\tLoss_D: 0.9603\tLoss_G: 0.2668\n",
      "[800/20000]\tLoss_D: 1.2217\tLoss_G: 0.2764\n",
      "[900/20000]\tLoss_D: 0.9751\tLoss_G: 0.4168\n",
      "[1000/20000]\tLoss_D: 0.9488\tLoss_G: 0.2173\n",
      "[1100/20000]\tLoss_D: 1.0963\tLoss_G: 0.2862\n",
      "[1200/20000]\tLoss_D: 0.8042\tLoss_G: 0.1657\n",
      "[1300/20000]\tLoss_D: 0.7598\tLoss_G: 0.2153\n",
      "[1400/20000]\tLoss_D: 0.7531\tLoss_G: 0.3976\n",
      "[1500/20000]\tLoss_D: 1.0152\tLoss_G: 0.2257\n",
      "[1600/20000]\tLoss_D: 0.7739\tLoss_G: 0.2131\n",
      "[1700/20000]\tLoss_D: 0.7638\tLoss_G: 0.2901\n",
      "[1800/20000]\tLoss_D: 0.9798\tLoss_G: 0.1239\n",
      "[1900/20000]\tLoss_D: 1.3205\tLoss_G: 0.1534\n",
      "[2000/20000]\tLoss_D: 0.7119\tLoss_G: 0.1554\n",
      "[2100/20000]\tLoss_D: 0.9848\tLoss_G: 0.1804\n",
      "[2200/20000]\tLoss_D: 0.8662\tLoss_G: 0.1224\n",
      "[2300/20000]\tLoss_D: 0.8907\tLoss_G: 0.2597\n",
      "[2400/20000]\tLoss_D: 0.7356\tLoss_G: 0.4877\n",
      "[2500/20000]\tLoss_D: 0.6413\tLoss_G: 0.1978\n",
      "[2600/20000]\tLoss_D: 0.6767\tLoss_G: 0.1662\n",
      "[2700/20000]\tLoss_D: 0.7201\tLoss_G: 0.2242\n",
      "[2800/20000]\tLoss_D: 0.9045\tLoss_G: 0.2158\n",
      "[2900/20000]\tLoss_D: 0.4212\tLoss_G: 0.1940\n",
      "[3000/20000]\tLoss_D: 0.6729\tLoss_G: 0.2407\n",
      "[3100/20000]\tLoss_D: 0.5695\tLoss_G: 0.2472\n",
      "[3200/20000]\tLoss_D: 0.6402\tLoss_G: 0.1935\n",
      "[3300/20000]\tLoss_D: 0.4455\tLoss_G: 0.1270\n",
      "[3400/20000]\tLoss_D: 0.5060\tLoss_G: 0.1897\n",
      "[3500/20000]\tLoss_D: 0.2833\tLoss_G: 0.1776\n",
      "[3600/20000]\tLoss_D: 0.7702\tLoss_G: 0.1741\n",
      "[3700/20000]\tLoss_D: 0.7038\tLoss_G: 0.1775\n",
      "[3800/20000]\tLoss_D: 0.3031\tLoss_G: 0.1931\n",
      "[3900/20000]\tLoss_D: 0.3971\tLoss_G: 0.1804\n",
      "[4000/20000]\tLoss_D: 0.2261\tLoss_G: 0.1663\n",
      "[4100/20000]\tLoss_D: 0.4453\tLoss_G: 0.2165\n",
      "[4200/20000]\tLoss_D: 0.6589\tLoss_G: 0.2011\n",
      "[4300/20000]\tLoss_D: 0.4446\tLoss_G: 0.1972\n",
      "[4400/20000]\tLoss_D: 0.5358\tLoss_G: 0.2199\n",
      "[4500/20000]\tLoss_D: 0.4048\tLoss_G: 0.2358\n",
      "[4600/20000]\tLoss_D: 0.1781\tLoss_G: 0.1966\n",
      "[4700/20000]\tLoss_D: 0.7668\tLoss_G: 0.1618\n",
      "[4800/20000]\tLoss_D: 0.3292\tLoss_G: 0.1827\n",
      "[4900/20000]\tLoss_D: 0.0857\tLoss_G: 0.2087\n",
      "[5000/20000]\tLoss_D: 0.2606\tLoss_G: 0.1759\n",
      "[5100/20000]\tLoss_D: 0.3248\tLoss_G: 0.2037\n",
      "[5200/20000]\tLoss_D: 0.7323\tLoss_G: 0.1335\n",
      "[5300/20000]\tLoss_D: 0.6089\tLoss_G: 0.1706\n",
      "[5400/20000]\tLoss_D: 0.6274\tLoss_G: 0.1961\n",
      "[5500/20000]\tLoss_D: 0.5661\tLoss_G: 0.2609\n",
      "[5600/20000]\tLoss_D: 0.7847\tLoss_G: 0.1951\n",
      "[5700/20000]\tLoss_D: 0.3439\tLoss_G: 0.2730\n",
      "[5800/20000]\tLoss_D: 0.4881\tLoss_G: 0.1953\n",
      "[5900/20000]\tLoss_D: 0.5113\tLoss_G: 0.2535\n",
      "[6000/20000]\tLoss_D: 0.6621\tLoss_G: 0.2091\n",
      "[6100/20000]\tLoss_D: 0.4651\tLoss_G: 0.1589\n",
      "[6200/20000]\tLoss_D: 0.7395\tLoss_G: 0.1853\n",
      "[6300/20000]\tLoss_D: 0.7509\tLoss_G: 0.1712\n",
      "[6400/20000]\tLoss_D: 0.6293\tLoss_G: 0.1602\n",
      "[6500/20000]\tLoss_D: 1.1502\tLoss_G: 0.2909\n",
      "[6600/20000]\tLoss_D: 0.6367\tLoss_G: 0.1830\n",
      "[6700/20000]\tLoss_D: 1.0060\tLoss_G: 0.2530\n",
      "[6800/20000]\tLoss_D: 0.8099\tLoss_G: 0.1428\n",
      "[6900/20000]\tLoss_D: 0.7129\tLoss_G: 0.1670\n",
      "[7000/20000]\tLoss_D: 0.6875\tLoss_G: 0.1874\n",
      "[7100/20000]\tLoss_D: 0.7379\tLoss_G: 0.1798\n",
      "[7200/20000]\tLoss_D: 0.7326\tLoss_G: 0.1701\n",
      "[7300/20000]\tLoss_D: 0.4667\tLoss_G: 0.3015\n",
      "[7400/20000]\tLoss_D: 0.3177\tLoss_G: 0.2179\n",
      "[7500/20000]\tLoss_D: 0.8852\tLoss_G: 0.2142\n",
      "[7600/20000]\tLoss_D: 0.5566\tLoss_G: 0.2989\n",
      "[7700/20000]\tLoss_D: 0.9179\tLoss_G: 0.1774\n",
      "[7800/20000]\tLoss_D: 0.2809\tLoss_G: 0.1731\n",
      "[7900/20000]\tLoss_D: 0.6618\tLoss_G: 0.1632\n",
      "[8000/20000]\tLoss_D: 0.4107\tLoss_G: 0.2263\n",
      "[8100/20000]\tLoss_D: 0.7878\tLoss_G: 0.1471\n",
      "[8200/20000]\tLoss_D: 0.4733\tLoss_G: 0.2452\n",
      "[8300/20000]\tLoss_D: 0.8246\tLoss_G: 0.3202\n",
      "[8400/20000]\tLoss_D: 0.8795\tLoss_G: 0.2336\n",
      "[8500/20000]\tLoss_D: 0.8001\tLoss_G: 0.2293\n",
      "[8600/20000]\tLoss_D: 0.5858\tLoss_G: 0.1777\n",
      "[8700/20000]\tLoss_D: 0.4084\tLoss_G: 0.1799\n",
      "[8800/20000]\tLoss_D: 0.6848\tLoss_G: 0.3694\n",
      "[8900/20000]\tLoss_D: 0.5314\tLoss_G: 0.1521\n",
      "[9000/20000]\tLoss_D: 0.7267\tLoss_G: 0.2040\n",
      "[9100/20000]\tLoss_D: 0.5138\tLoss_G: 0.1775\n",
      "[9200/20000]\tLoss_D: 0.5019\tLoss_G: 0.1712\n",
      "[9300/20000]\tLoss_D: 0.6042\tLoss_G: 0.1907\n",
      "[9400/20000]\tLoss_D: 0.6492\tLoss_G: 0.2219\n",
      "[9500/20000]\tLoss_D: 0.3749\tLoss_G: 0.4263\n",
      "[9600/20000]\tLoss_D: 0.6791\tLoss_G: 0.2291\n",
      "[9700/20000]\tLoss_D: 0.4511\tLoss_G: 0.1478\n",
      "[9800/20000]\tLoss_D: 0.7179\tLoss_G: 0.1833\n",
      "[9900/20000]\tLoss_D: 0.8549\tLoss_G: 0.2791\n",
      "[10000/20000]\tLoss_D: 0.3582\tLoss_G: 0.2012\n",
      "[10100/20000]\tLoss_D: 0.7120\tLoss_G: 0.1741\n",
      "[10200/20000]\tLoss_D: 0.6698\tLoss_G: 0.2205\n",
      "[10300/20000]\tLoss_D: 0.3139\tLoss_G: 0.1336\n",
      "[10400/20000]\tLoss_D: 0.2935\tLoss_G: 0.2145\n",
      "[10500/20000]\tLoss_D: 0.8468\tLoss_G: 0.5260\n",
      "[10600/20000]\tLoss_D: 0.8475\tLoss_G: 0.1201\n",
      "[10700/20000]\tLoss_D: 0.8889\tLoss_G: 0.1672\n",
      "[10800/20000]\tLoss_D: 0.2467\tLoss_G: 0.2623\n",
      "[10900/20000]\tLoss_D: 0.3360\tLoss_G: 0.3026\n",
      "[11000/20000]\tLoss_D: 0.5200\tLoss_G: 0.1474\n",
      "[11100/20000]\tLoss_D: 0.5516\tLoss_G: 0.2448\n",
      "[11200/20000]\tLoss_D: 0.4581\tLoss_G: 0.4134\n",
      "[11300/20000]\tLoss_D: 0.7758\tLoss_G: 0.2753\n",
      "[11400/20000]\tLoss_D: 0.7758\tLoss_G: 0.1793\n",
      "[11500/20000]\tLoss_D: 0.5297\tLoss_G: 0.2242\n",
      "[11600/20000]\tLoss_D: 0.5765\tLoss_G: 0.2351\n",
      "[11700/20000]\tLoss_D: 0.2823\tLoss_G: 0.1690\n",
      "[11800/20000]\tLoss_D: 0.6411\tLoss_G: 0.1572\n",
      "[11900/20000]\tLoss_D: 0.7635\tLoss_G: 0.1690\n",
      "[12000/20000]\tLoss_D: 0.7455\tLoss_G: 0.2126\n",
      "[12100/20000]\tLoss_D: 0.2379\tLoss_G: 0.2308\n",
      "[12200/20000]\tLoss_D: 0.4185\tLoss_G: 0.4386\n",
      "[12300/20000]\tLoss_D: 0.4481\tLoss_G: 0.1765\n",
      "[12400/20000]\tLoss_D: 0.8202\tLoss_G: 0.2253\n",
      "[12500/20000]\tLoss_D: 0.3268\tLoss_G: 0.1520\n",
      "[12600/20000]\tLoss_D: 0.2241\tLoss_G: 0.2271\n",
      "[12700/20000]\tLoss_D: 0.5845\tLoss_G: 0.1880\n",
      "[12800/20000]\tLoss_D: 0.3843\tLoss_G: 0.2888\n",
      "[12900/20000]\tLoss_D: 1.2988\tLoss_G: 0.1928\n",
      "[13000/20000]\tLoss_D: 0.2519\tLoss_G: 0.1316\n",
      "[13100/20000]\tLoss_D: 0.4727\tLoss_G: 0.1865\n",
      "[13200/20000]\tLoss_D: 0.5836\tLoss_G: 0.1909\n",
      "[13300/20000]\tLoss_D: 0.5776\tLoss_G: 0.1522\n",
      "[13400/20000]\tLoss_D: 0.3677\tLoss_G: 0.1828\n",
      "[13500/20000]\tLoss_D: 0.3911\tLoss_G: 0.2086\n",
      "[13600/20000]\tLoss_D: 0.6901\tLoss_G: 0.3300\n",
      "[13700/20000]\tLoss_D: 0.7176\tLoss_G: 0.1965\n",
      "[13800/20000]\tLoss_D: 0.4278\tLoss_G: 0.3013\n",
      "[13900/20000]\tLoss_D: 0.1924\tLoss_G: 0.1818\n",
      "[14000/20000]\tLoss_D: 0.5846\tLoss_G: 0.1720\n",
      "[14100/20000]\tLoss_D: 0.4322\tLoss_G: 0.3403\n",
      "[14200/20000]\tLoss_D: 0.1320\tLoss_G: 0.1400\n",
      "[14300/20000]\tLoss_D: 0.4182\tLoss_G: 0.1861\n",
      "[14400/20000]\tLoss_D: 0.5954\tLoss_G: 0.2367\n",
      "[14500/20000]\tLoss_D: 0.5261\tLoss_G: 0.2111\n",
      "[14600/20000]\tLoss_D: 0.4585\tLoss_G: 0.1537\n",
      "[14700/20000]\tLoss_D: 0.2664\tLoss_G: 0.2262\n",
      "[14800/20000]\tLoss_D: 0.3571\tLoss_G: 0.1478\n",
      "[14900/20000]\tLoss_D: 0.7226\tLoss_G: 0.1739\n",
      "[15000/20000]\tLoss_D: 0.3056\tLoss_G: 0.3400\n",
      "[15100/20000]\tLoss_D: 0.5582\tLoss_G: 0.1610\n",
      "[15200/20000]\tLoss_D: 0.6225\tLoss_G: 0.1489\n",
      "[15300/20000]\tLoss_D: 0.8327\tLoss_G: 0.2009\n",
      "[15400/20000]\tLoss_D: 0.5047\tLoss_G: 0.2411\n",
      "[15500/20000]\tLoss_D: 0.4417\tLoss_G: 0.1862\n",
      "[15600/20000]\tLoss_D: 0.7970\tLoss_G: 0.1574\n",
      "[15700/20000]\tLoss_D: 0.5067\tLoss_G: 0.2054\n",
      "[15800/20000]\tLoss_D: 0.6409\tLoss_G: 0.1613\n",
      "[15900/20000]\tLoss_D: 0.4428\tLoss_G: 0.1516\n",
      "[16000/20000]\tLoss_D: 0.6296\tLoss_G: 0.1793\n",
      "[16100/20000]\tLoss_D: 0.2990\tLoss_G: 0.2022\n",
      "[16200/20000]\tLoss_D: 0.3453\tLoss_G: 0.1894\n",
      "[16300/20000]\tLoss_D: 0.1452\tLoss_G: 0.1859\n",
      "[16400/20000]\tLoss_D: 0.7893\tLoss_G: 0.2703\n",
      "[16500/20000]\tLoss_D: 0.3491\tLoss_G: 0.2103\n",
      "[16600/20000]\tLoss_D: 0.2286\tLoss_G: 0.2209\n",
      "[16700/20000]\tLoss_D: 0.3325\tLoss_G: 0.1885\n",
      "[16800/20000]\tLoss_D: 0.5284\tLoss_G: 0.1703\n",
      "[16900/20000]\tLoss_D: 0.3210\tLoss_G: 0.1307\n",
      "[17000/20000]\tLoss_D: 0.5309\tLoss_G: 0.1967\n",
      "[17100/20000]\tLoss_D: 0.6819\tLoss_G: 0.2124\n",
      "[17200/20000]\tLoss_D: 0.4504\tLoss_G: 0.1777\n",
      "[17300/20000]\tLoss_D: 0.5652\tLoss_G: 0.2162\n",
      "[17400/20000]\tLoss_D: 0.3450\tLoss_G: 0.2034\n",
      "[17500/20000]\tLoss_D: 0.3441\tLoss_G: 0.2909\n",
      "[17600/20000]\tLoss_D: 0.8142\tLoss_G: 0.2947\n",
      "[17700/20000]\tLoss_D: 0.3967\tLoss_G: 0.1990\n",
      "[17800/20000]\tLoss_D: 0.4263\tLoss_G: 0.1735\n",
      "[17900/20000]\tLoss_D: 0.5879\tLoss_G: 0.1985\n",
      "[18000/20000]\tLoss_D: 0.7155\tLoss_G: 0.2150\n",
      "[18100/20000]\tLoss_D: 0.5360\tLoss_G: 0.2166\n",
      "[18200/20000]\tLoss_D: 0.5152\tLoss_G: 0.2373\n",
      "[18300/20000]\tLoss_D: 0.5646\tLoss_G: 0.2656\n",
      "[18400/20000]\tLoss_D: 0.4636\tLoss_G: 0.2218\n",
      "[18500/20000]\tLoss_D: 0.2926\tLoss_G: 0.2179\n",
      "[18600/20000]\tLoss_D: 0.4626\tLoss_G: 0.1814\n",
      "[18700/20000]\tLoss_D: 0.5807\tLoss_G: 0.2177\n",
      "[18800/20000]\tLoss_D: 0.7800\tLoss_G: 0.2104\n",
      "[18900/20000]\tLoss_D: 0.6150\tLoss_G: 0.2231\n",
      "[19000/20000]\tLoss_D: 0.2542\tLoss_G: 0.2169\n",
      "[19100/20000]\tLoss_D: 0.5252\tLoss_G: 0.1175\n",
      "[19200/20000]\tLoss_D: 0.1686\tLoss_G: 0.1858\n",
      "[19300/20000]\tLoss_D: 0.2321\tLoss_G: 0.2356\n",
      "[19400/20000]\tLoss_D: 0.7282\tLoss_G: 0.1960\n",
      "[19500/20000]\tLoss_D: 0.4445\tLoss_G: 0.1643\n",
      "[19600/20000]\tLoss_D: 0.7797\tLoss_G: 0.2735\n",
      "[19700/20000]\tLoss_D: 0.4557\tLoss_G: 0.1773\n",
      "[19800/20000]\tLoss_D: 0.1438\tLoss_G: 0.1689\n",
      "[19900/20000]\tLoss_D: 0.5037\tLoss_G: 0.1559\n"
     ]
    }
   ],
   "source": [
    "iterations = 20000\n",
    "for i in range(iterations):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    # print('Memory usage when training begins: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    \n",
    "    # print(\"****************train discriminator*****************\")\n",
    "    encoder_data, discriminator_data, yhat = dloader.get_train_batch(16)\n",
    "\n",
    "    encoder_data = torch.from_numpy(encoder_data).float().to(device)\n",
    "    # print(\"encoder_data size: {} bytes => {} GB\".format(encoder_data.element_size() * encoder_data.nelement(),\n",
    "    #                                                     encoder_data.element_size() * encoder_data.nelement()/1e9))\n",
    "    \n",
    "    discriminator_data = torch.from_numpy(discriminator_data).float().to(device)\n",
    "    # print(\"discriminator_data size: {} bytes => {} GB\".format(discriminator_data.element_size() * discriminator_data.nelement(),\n",
    "    #                                                           discriminator_data.element_size() * discriminator_data.nelement()/1e9))\n",
    "    \n",
    "    yhat = torch.from_numpy(yhat).float().to(device)\n",
    "    # print(\"yhat size: {} bytes => {} GB\".format(yhat.element_size() * yhat.nelement(),\n",
    "    #                                             yhat.element_size() * yhat.nelement()/1e9))\n",
    "    \n",
    "    # expected_seq = discriminator_data[:, 50:, :, :]\n",
    "    # print(\"expected_seq size: {} bytes => {} GB\".format(expected_seq.element_size() * expected_seq.nelement(),\n",
    "    #                                                     expected_seq.element_size() * expected_seq.nelement()/1e9))\n",
    "    for param in discriminator.parameters():\n",
    "        param.grad = None\n",
    "    # optimizerD.zero_grad()\n",
    "    # print('Memory usage after discriminator zero_grad: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    # with torch.cuda.amp.autocast():\n",
    "    d_logits_real = discriminator.forward(discriminator_data, yhat)\n",
    "    # print('Memory usage after d_logits_real forward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "\n",
    "    d_loss_real = D_criterion(d_logits_real, torch.ones_like(d_logits_real))\n",
    "    # print('Memory usage after d_loss_real: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "\n",
    "    d_loss_real.backward()\n",
    "    # print('Memory usage after d_loss_real backward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    # with torch.cuda.amp.autocast():\n",
    "    predicted_seq, predicted_action, generated_sample = generator.forward(encoder_data, discriminator_data)\n",
    "    \n",
    "    # print('Memory usage after generator forward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    d_logits_fake = discriminator.forward(generated_sample, yhat)\n",
    "    # print('Memory usage after d_logits_fake forward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "\n",
    "    d_loss_fake = D_criterion(d_logits_fake, torch.zeros_like(d_logits_fake))\n",
    "    # print('Memory usage after d_loss_fake : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "\n",
    "    d_loss_fake.backward()\n",
    "    # print('Memory usage after d_loss_fake backward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "\n",
    "    loss_discriminator = d_loss_real + d_loss_fake\n",
    "    # print('Memory usage after loss_discriminator summed: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    optimizerD.step()\n",
    "    # print('Memory usage after optimizerD stepped: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    \n",
    "    # print(\"****************train generator*****************\")\n",
    "    encoder_data, discriminator_data, yhat = dloader.get_train_batch(16)\n",
    "\n",
    "    encoder_data = torch.from_numpy(encoder_data).float().to(device)\n",
    "    # print(\"encoder_data size: {} bytes => {} GB\".format(encoder_data.element_size() * encoder_data.nelement(),\n",
    "    #                                                     encoder_data.element_size() * encoder_data.nelement()/1e9))\n",
    "    \n",
    "    discriminator_data = torch.from_numpy(discriminator_data).float().to(device)\n",
    "    # print(\"discriminator_data size: {} bytes => {} GB\".format(discriminator_data.element_size() * discriminator_data.nelement(),\n",
    "    #                                                           discriminator_data.element_size() * discriminator_data.nelement()/1e9))\n",
    "    \n",
    "    yhat = torch.from_numpy(yhat).float().to(device)\n",
    "    # print(\"yhat size: {} bytes => {} GB\".format(yhat.element_size() * yhat.nelement(),\n",
    "    #                                             yhat.element_size() * yhat.nelement()/1e9))\n",
    "    \n",
    "    expected_seq = discriminator_data[:, 50:, :, :]\n",
    "    # print(\"expected_seq size: {} bytes => {} GB\".format(expected_seq.element_size() * expected_seq.nelement(),\n",
    "    #                                                     expected_seq.element_size() * expected_seq.nelement()/1e9))\n",
    "    \n",
    "    for param in generator.parameters():\n",
    "        param.grad = None\n",
    "    # optimizerG.zero_grad()\n",
    "    # with torch.cuda.amp.autocast():\n",
    "    predicted_seq, predicted_action, generated_sample = generator.forward(encoder_data, discriminator_data)\n",
    "    # print('Memory usage after generator forward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    ReconstructError = G_criterion(predicted_seq, expected_seq)\n",
    "    # print('Memory usage after ReconstructError : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    ReconstructError.backward(retain_graph=True)\n",
    "    # print('Memory usage after ReconstructError backward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    # with torch.cuda.amp.autocast():\n",
    "    d_logits_fake = discriminator.forward(generated_sample, yhat)\n",
    "    # print('Memory usage after discriminator foward : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    g_loss = D_criterion(d_logits_fake, torch.ones_like(d_logits_fake)) * torch.tensor(0.01)\n",
    "    # print('Memory usage after g_loss : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    g_loss.backward()\n",
    "    # print('Memory usage after g_loss backward: {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    loss_generator = ReconstructError + g_loss\n",
    "    # print('Memory usage after loss_generator summed : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    \n",
    "    optimizerG.step()\n",
    "    # print('Memory usage after optimizerG stepped : {} bytes => {} GB'.format(torch.cuda.memory_allocated(device=device), \n",
    "    #                                                torch.cuda.memory_allocated(device=device)/1e9))\n",
    "    \n",
    "    # Output training stats\n",
    "    if i % 100 == 0:\n",
    "        print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "            % (i, iterations, loss_discriminator.item(), loss_generator.item()))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'save_dir/generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(discriminator.state_dict(), 'save_dir/discriminator.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e9b5e93101e5958f9cd028a9f43ed128e885f27a05c22831a3d71acc3bca11d"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
